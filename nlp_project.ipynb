{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "from nltk import RegexpTokenizer\n",
    "import preprocess #Only executing the import the preprocessing and tokenization will be applied\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This data was preprocessed with the code in preprocess.py\n",
    "\n",
    "train_set = pd.read_parquet('./preprocessed_and_tokenized_data/preprocessed_train_dataset.parquet')\n",
    "test_set  = pd.read_parquet('./preprocessed_and_tokenized_data/preprocessed_test_dataset.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data vectorization\n",
    "vectorizer = CountVectorizer()\n",
    "fit = vectorizer.fit(train_set['processed_text'][i] for i in range(len(train_set)))\n",
    "X_train = vectorizer.transform(train_set['processed_text'][i] for i in range(len(train_set)))\n",
    "y_train = train_set['label']\n",
    "X_test = vectorizer.transform(test_set['processed_text'][i] for i in range(len(test_set)))\n",
    "y_test = test_set['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_f1 = 0\n",
    "for C in [0.1,0.25,0.5,1,2,5]:\n",
    "    for tol in [0.000001,0.0001,0.01,0.1,0.15,0.175]:\n",
    "        model     = LinearSVC(tol=tol, C=C, multi_class='ovr', random_state=2024, max_iter=1000)\n",
    "        trained   = model.fit(X_train, y_train)\n",
    "        preds     = fit.predict(X_test)\n",
    "        f1        = f1_score(y_test, preds, average = 'micro')\n",
    "        if best_f1 < f1:\n",
    "            best_f1     = f1\n",
    "            best_params = [C,tol]\n",
    "            best_model  = trained\n",
    "print(f'Best f1 obtained = {best_f1}\\n')\n",
    "print(f'Best value for C: {best_params[0]}, best value for tol: {best_params[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_f1 = 0\n",
    "for C in [0.1,0.25,0.5,1,2,5]:\n",
    "    for tol in [0.000001,0.0001,0.01,0.1,0.15,0.175]:\n",
    "        model = LogisticRegression(tol=tol, C=C, multi_class='ovr', random_state=2024, max_iter=1000)\n",
    "        fit   = model.fit(X_train, y_train)\n",
    "        preds = fit.predict(X_test)\n",
    "        f1    = f1_score(y_test, preds, average = 'micro')\n",
    "        if best_f1 < f1:\n",
    "            best_f1     = f1\n",
    "            best_params = [C,tol]\n",
    "            best_model  = fit\n",
    "print(f'Best f1 obtained = {best_f1}\\n')\n",
    "print(f'Best value for C: {best_params[0]}, best value for tol: {best_params[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model = MLPClassifier(hidden_layer_sizes=(100,), activation = 'tanh', solver = 'adam')\n",
    "model_f = model.fit(X_train, y_train)\n",
    "preds = model_f.predict(X_test)\n",
    "f1 = f1_score(y_test, preds, average = 'micro')\n",
    "print(f'f1 obtained = {f1}\\n')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
